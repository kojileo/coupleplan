# Gemini 2.5 思考トークン問題と解決策

## 問題の概要

`gemini-2.5-flash` や `gemini-2.5-pro` を使用すると、**思考トークン**が大量に消費され、2000トークン制限では出力が生成されません。

---

## 🔍 問題の詳細

### エラーログの例

```
"promptTokenCount": 95,
"totalTokenCount": 2094,
"thoughtsTokenCount": 1999,  ← 問題の原因
"finishReason": "MAX_TOKENS"
```

### 内訳

| 項目       | トークン数 | 説明                    |
| ---------- | ---------- | ----------------------- |
| プロンプト | 95         | 入力（最適化済み）      |
| **思考**   | **1999**   | **モデルの内部思考** ⚠️ |
| 出力       | 0          | 出力用トークンなし      |
| **合計**   | **2094**   | **制限超過**            |

### 問題点

1. Gemini 2.5系は「思考モード」を使用
2. 内部思考だけで約2000トークン消費
3. 実際の出力用トークンがほぼゼロ
4. `MAX_TOKENS`エラーで生成失敗

---

## ✅ 解決策

### 推奨モデルに変更

`.env.local` を以下のように設定：

```env
AI_PROVIDER=gemini
GEMINI_API_KEY=your_gemini_api_key_here
AI_MODEL=gemini-1.5-flash-latest
AI_MAX_TOKENS=2000
AI_TEMPERATURE=0.7
```

**重要**: `gemini-1.5-flash-latest` に変更してください。

---

## 📊 モデル比較

### ✅ 推奨モデル

#### gemini-1.5-flash-latest（最推奨）⭐

- **思考トークン**: なし
- **トークン効率**: 最高
- **生成時間**: 10-15秒
- **品質**: 高品質
- **コスト**: 無料枠で十分

#### gemini-1.5-pro-latest

- **思考トークン**: なし
- **トークン効率**: 良好
- **生成時間**: 15-20秒
- **品質**: 最高品質
- **コスト**: 無料枠で十分

### ❌ 非推奨モデル

#### gemini-2.5-flash

- **思考トークン**: 約2000 ⚠️
- **トークン効率**: 悪い
- **問題**: 2000トークン制限では動作不可
- **使用**: **避けるべき**

#### gemini-2.5-pro

- **思考トークン**: 約2000 ⚠️
- **トークン効率**: 悪い
- **問題**: 2000トークン制限では動作不可
- **使用**: **避けるべき**

---

## 🛠️ 修正内容

### 1. デフォルトモデルを変更 ✅

```typescript
// 修正前
defaultModel = 'gemini-1.5-pro-latest';

// 修正後
defaultModel = 'gemini-1.5-flash-latest';
```

### 2. エラーメッセージを改善 ✅

思考トークンが多い場合、具体的な解決策を表示：

```
⚠️ 思考トークン（1999）が大量に使用されています。
現在のモデル: gemini-2.5-flash

解決策: .env.local で以下を設定してください：
AI_MODEL=gemini-1.5-flash-latest

gemini-2.5系は思考トークンを使うため、2000トークン制限では動作しません。
```

### 3. ドキュメント更新 ✅

- `README.md` - 推奨モデル変更
- `Docs/TOKEN_OPTIMIZATION.md` - 2.5系の警告追加
- `Docs/GEMINI_2_5_ISSUE.md` - 本ドキュメント作成

---

## 🎯 実際のトークン使用量

### gemini-1.5-flash-latest（推奨）

```
プロンプト: 95トークン
出力: 800-1200トークン
合計: 895-1295トークン ✅

→ 2000トークン制限内で余裕あり
```

### gemini-2.5-flash（非推奨）

```
プロンプト: 95トークン
思考: 1999トークン ⚠️
出力: 0トークン
合計: 2094トークン ❌

→ 制限超過、出力なし
```

---

## 🚀 動作確認

### 1. `.env.local` を更新

```env
AI_MODEL=gemini-1.5-flash-latest
```

### 2. 開発サーバーを再起動

```bash
# サーバーを停止（Ctrl + C）
npm run dev
```

### 3. プラン生成をテスト

期待される結果：

```
[Gemini API] リクエスト送信: gemini-1.5-flash-latest
[Gemini API] レスポンス受信: 200
[Gemini API] 終了理由: STOP  ✅
[Gemini API] 抽出成功。テキスト長: 1000
```

---

## 💡 なぜ2.5系は思考トークンを使うのか？

Gemini 2.5シリーズは新しい「**思考モード**」を実装しています：

1. プロンプトを受け取る
2. **内部で推論・思考を行う**（約2000トークン）
3. 最終的な回答を生成

### メリット

- より高度な推論
- 複雑な問題の解決

### デメリット

- トークン消費が多い
- 2000トークン制限では使用不可
- 生成時間が長い

### 結論

本アプリケーションでは**トークン効率を重視**するため、1.5系を使用します。

---

## 📋 トラブルシューティング

### エラー: "思考トークン（1999）が大量に使用されています"

**原因**: gemini-2.5系を使用している

**解決策**:

1. `.env.local` で `AI_MODEL=gemini-1.5-flash-latest` に変更
2. 開発サーバーを再起動

### エラー: まだMAX_TOKENSエラーが出る

**確認事項**:

1. `.env.local` の設定を確認
   ```bash
   # PowerShell
   $env:AI_MODEL
   ```
2. サーバーを完全に再起動
3. ブラウザのキャッシュをクリア

---

## 🎯 本番環境での設定

### Vercel環境変数

Vercelダッシュボードで設定：

| 変数名           | 値                           |
| ---------------- | ---------------------------- |
| `AI_PROVIDER`    | `gemini`                     |
| `GEMINI_API_KEY` | (APIキー)                    |
| `AI_MODEL`       | `gemini-1.5-flash-latest` ⭐ |
| `AI_MAX_TOKENS`  | `2000`                       |
| `AI_TEMPERATURE` | `0.7`                        |

**重要**: `AI_MODEL` を必ず `gemini-1.5-flash-latest` に設定してください。

---

## ✨ まとめ

### 問題

- ✅ Gemini 2.5系は思考トークンで約2000トークン消費
- ✅ 2000トークン制限では出力が生成されない

### 解決策

- ✅ `gemini-1.5-flash-latest` を使用
- ✅ トークン効率が良く、高品質
- ✅ 10-15秒で生成完了

### 推奨設定

```env
AI_MODEL=gemini-1.5-flash-latest
AI_MAX_TOKENS=2000
```

---

**最終更新**: 2025年10月9日  
**バージョン**: v0.4.1  
**変更内容**: Gemini 2.5思考トークン問題の解決
